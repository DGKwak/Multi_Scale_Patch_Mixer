defaults:
  - model: MLP_Mixer
  - loss: loss
  - data:
      - STFT
      - transform
  - _self_

experiment_name: "Original_MLP-Mixer"
epochs: 200
learning_rate: 1e-3
batch_size: 32
num_workers: 8
weight_decay: 1e-4
csv_path: "/home/eslab/Vscode/MultiPatchdopplerMLP/results"
confusion_path: "/home/eslab/Vscode/MultiPatchdopplerMLP/confusion"
best_model_path: "/home/eslab/Vscode/MultiPatchdopplerMLP/checkpoints"
